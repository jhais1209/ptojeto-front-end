import requests
from bs4 import BeautifulSoup
import pandas as pd

# Lista para os dados
data = []

# Base URL
base_url = "https://books.toscrape.com/catalogue/page-{}.html"

# Loop das páginas
page = 1
while True:
    url = base_url.format(page)
    response = requests.get(url)

    # Verificar se a página existe
    if response.status_code != 200:
        print(f"Fim das páginas detectado na página {page}.")
        break

    soup = BeautifulSoup(response.content, 'html.parser')
    books = soup.find_all("article", class_="product_pod")

    # Verificar se há livros na página
    if not books:
        print(f"Nenhum livro encontrado na página {page}. Encerrando o loop.")
        break

    for book in books:
        title = book.h3.a['title']
        price = book.find("p", class_="price_color").text
        availability = book.find("p", class_="instock availability").text.strip()
        data.append({"Title": title, "Price": price, "Availability": availability})

    page += 1

# Criação do DataFrame
df = pd.DataFrame(data)

# Tratamento de dados
# Remoção dos símbolos monetários e conversão de preços para float
df['Price'] = df['Price'].str.replace('£', '').astype(float)

# Salvando os dados em um arquivo CSV
df.to_csv("books_data.csv", index=False)

print(f"Arquivo gerado: books_data.csv com {len(df)} livros")
print(df)

from google.colab import files
files.download("books_data.csv")